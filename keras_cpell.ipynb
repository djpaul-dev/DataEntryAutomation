{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "\n",
    "# keras-ocr will automatically download pretrained\n",
    "# weights for the detector and recognizer.\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "\n",
    "# Get a set of three example images\n",
    "images = [\n",
    "    keras_ocr.tools.read(url) for url in [\n",
    "        '500 PRS + Slip Image & Data/Dr. PRS (300)/PRS208C4002621.jpg',\n",
    "        '500 PRS + Slip Image & Data/Dr. PRS (300)/PRS208C4017521.jpg'        \n",
    "    ]\n",
    "]\n",
    "\n",
    "# Each list of predictions in prediction_groups is a list of\n",
    "# (word, box) tuples.\n",
    "prediction_groups = pipeline.recognize(images)\n",
    "\n",
    "# Plot the predictions\n",
    "fig, axs = plt.subplots(nrows=len(images), figsize=(20, 20))\n",
    "for ax, image, predictions in zip(axs, images, prediction_groups):\n",
    "    keras_ocr.tools.drawAnnotations(image=image, predictions=predictions, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read .xlsx file\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "df = pd.read_excel('500 PRS + Slip Image & Data/Physician Database 500 PRS.xlsx')\n",
    "dr_names = df[\"PHY_NM\"].apply(lambda x: x.lower().split(\" \")).tolist()\n",
    "dr_names\n",
    "\n",
    "dr_name_set = set()\n",
    "for dr_name in dr_names:\n",
    "    dr_name_set.update(dr_name)\n",
    "dr_name_set\n",
    "\n",
    "# Write dr. names to a file for cspell spell checking\n",
    "with open(\"custom-words.txt\", \"w\") as f:\n",
    "    for dr_name in dr_name_set:\n",
    "        f.write(dr_name + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_ocr, os, subprocess\n",
    "from tqdm import tqdm\n",
    "\n",
    "pipeline = keras_ocr.pipeline.Pipeline()\n",
    "DIR = \"dr_prescriptions\"\n",
    "\n",
    "def get_predictions_list(image_paths: list[str]) -> None:\n",
    "    if not os.path.exists(DIR):\n",
    "        os.makedirs(DIR)\n",
    "\n",
    "    for img_path in tqdm(image_paths):\n",
    "        image = [keras_ocr.tools.read(img_path)]\n",
    "        prediction_groups = pipeline.recognize(image)\n",
    "        text = \" \".join([word for word, box in prediction_groups[0]])\n",
    "        filename = os.path.join(DIR, f\"{os.path.splitext(os.path.basename(img_path))[0]}.txt\")\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(text)\n",
    "\n",
    "\n",
    "def make_corrections(text_path):\n",
    "    result = subprocess.run([\"./cspell_script.sh\", text_path], capture_output=True)\n",
    "    words_to_corrections = {}\n",
    "    errors = result.stdout.splitlines()\n",
    "    for error in errors:\n",
    "        error = error.decode(\"utf-8\")\n",
    "        mistake = error.split(\" \")[4][1:-1]\n",
    "        corrections = error.split(\"Suggestions: \")[-1]\n",
    "        best_correction = corrections.split(\", \")[0][1:]\n",
    "        words_to_corrections[mistake] = best_correction\n",
    "\n",
    "    with open(text_path, \"r\") as f:\n",
    "        text = f.read()\n",
    "    \n",
    "    for mistake, correction in words_to_corrections.items():\n",
    "        text = text.replace(mistake, correction)\n",
    "\n",
    "    with open(text_path, \"w\") as f:\n",
    "        f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filecount = 50\n",
    "dir_path = \"500 PRS + Slip Image & Data/Dr. PRS (300)\"\n",
    "get_predictions_list([os.path.join(dir_path, img) for img in os.listdir(dir_path)[:filecount]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = \"dr_prescriptions\"\n",
    "for text_file in os.listdir(dir_path):\n",
    "    make_corrections(os.path.join(dir_path, text_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
